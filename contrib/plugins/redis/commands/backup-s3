#!/bin/bash
SERVICE_NAME="$1"
S3_BUCKET="$2"
S3_PREFIX="${3:-redis-backups}"

echo "-----> Backing up Redis RDB to S3 for $SERVICE_NAME"

# Source helper functions
source /opt/gokku/scripts/plugin-helpers.sh

# Check if container exists
if ! container_exists "$SERVICE_NAME"; then
    echo "Service '$SERVICE_NAME' not found"
    exit 1
fi

# Check if container is running
if ! container_is_running "$SERVICE_NAME"; then
    echo "Service '$SERVICE_NAME' is not running"
    exit 1
fi

# Check if AWS CLI is available
if ! command_exists aws; then
    echo "AWS CLI not found. Please install AWS CLI first."
    exit 1
fi

# Check if S3 bucket is provided
if [ -z "$S3_BUCKET" ]; then
    echo "Usage: gokku redis:backup-s3 <service> <s3-bucket> [s3-prefix]"
    echo "Example: gokku redis:backup-s3 redis-cache my-backup-bucket redis-backups"
    exit 1
fi

# Get Redis password
REDIS_PASSWORD=$(get_service_config "$SERVICE_NAME" | grep -o '"password":"[^"]*"' | cut -d'"' -f4)

echo "-----> Triggering Redis BGSAVE to create RDB snapshot"

# Trigger Redis BGSAVE to create a fresh RDB file
BGSAVE_RESULT=$(docker exec "$SERVICE_NAME" redis-cli --no-auth-warning -a "$REDIS_PASSWORD" BGSAVE 2>/dev/null)

if [ "$BGSAVE_RESULT" != "OK" ]; then
    echo "Failed to trigger BGSAVE: $BGSAVE_RESULT"
    exit 1
fi

echo "-----> Waiting for BGSAVE to complete"

# Wait for BGSAVE to complete (check every 2 seconds, max 60 seconds)
for i in {1..30}; do
    LAST_SAVE=$(docker exec "$SERVICE_NAME" redis-cli --no-auth-warning -a "$REDIS_PASSWORD" LASTSAVE 2>/dev/null)
    BGSAVE_IN_PROGRESS=$(docker exec "$SERVICE_NAME" redis-cli --no-auth-warning -a "$REDIS_PASSWORD" INFO persistence 2>/dev/null | grep rdb_bgsave_in_progress | cut -d: -f2 | tr -d '\r')

    if [ "$BGSAVE_IN_PROGRESS" = "0" ]; then
        break
    fi

    if [ $i -eq 30 ]; then
        echo "BGSAVE timeout - proceeding with available RDB file"
        break
    fi

    sleep 2
done

echo "-----> BGSAVE completed"

# Generate backup filename with timestamp
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILENAME="${SERVICE_NAME}_backup_${TIMESTAMP}.rdb"
S3_KEY="${S3_PREFIX}/${SERVICE_NAME}/${BACKUP_FILENAME}"

echo "-----> Uploading RDB file to S3: s3://$S3_BUCKET/$S3_KEY"

# Copy RDB file from container to local temp file
TEMP_FILE="/tmp/${BACKUP_FILENAME}"
docker cp "$SERVICE_NAME:/data/dump.rdb" "$TEMP_FILE"

if [ ! -f "$TEMP_FILE" ]; then
    echo "Failed to copy RDB file from container"
    exit 1
fi

# Upload to S3
if aws s3 cp "$TEMP_FILE" "s3://$S3_BUCKET/$S3_KEY"; then
    echo "-----> Backup uploaded successfully to s3://$S3_BUCKET/$S3_KEY"

    # Get file size
    FILE_SIZE=$(du -h "$TEMP_FILE" | cut -f1)
    echo "       Backup size: $FILE_SIZE"

    # Clean up temp file
    rm -f "$TEMP_FILE"

    echo "-----> Redis backup to S3 completed successfully"
else
    echo "Failed to upload backup to S3"
    rm -f "$TEMP_FILE"
    exit 1
fi
